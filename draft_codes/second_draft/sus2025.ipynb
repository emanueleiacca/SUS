{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12176969,"sourceType":"datasetVersion","datasetId":7669125}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SUS2025","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade imbalanced-learn>=0.12.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:24:07.271231Z","iopub.execute_input":"2025-06-16T00:24:07.271474Z","iopub.status.idle":"2025-06-16T00:24:15.886240Z","shell.execute_reply.started":"2025-06-16T00:24:07.271450Z","shell.execute_reply":"2025-06-16T00:24:15.885535Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install xgboost --upgrade","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:24:15.887162Z","iopub.execute_input":"2025-06-16T00:24:15.887409Z","iopub.status.idle":"2025-06-16T00:24:28.750084Z","shell.execute_reply.started":"2025-06-16T00:24:15.887385Z","shell.execute_reply":"2025-06-16T00:24:28.749352Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nCollecting xgboost\n  Downloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xgboost) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xgboost) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xgboost) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xgboost) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xgboost) (2024.2.0)\nDownloading xgboost-3.0.2-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xgboost\n  Attempting uninstall: xgboost\n    Found existing installation: xgboost 2.0.3\n    Uninstalling xgboost-2.0.3:\n      Successfully uninstalled xgboost-2.0.3\nSuccessfully installed xgboost-3.0.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\nfrom sklearn.model_selection import train_test_split\nimport networkx as nx\nfrom collections import Counter, defaultdict\n\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:24:28.752313Z","iopub.execute_input":"2025-06-16T00:24:28.752522Z","iopub.status.idle":"2025-06-16T00:24:30.587741Z","shell.execute_reply.started":"2025-06-16T00:24:28.752501Z","shell.execute_reply":"2025-06-16T00:24:30.587171Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### 1. Dataset Analysis ","metadata":{}},{"cell_type":"code","source":"class MoneyLaunderingPreprocessor:\n    def __init__(self):\n        self.scalers = {}\n        self.label_encoders = {}\n        self.account_features = {}\n        self.network_features = {}\n        self.fitted = False\n        self.column_mapping = {}  # To handle column name variations\n        \n    def standardize_column_names(self, df):\n        \"\"\"Standardize column names to handle variations\"\"\"\n        df_clean = df.copy()\n        \n        # Define expected column mappings\n        column_mappings = {\n            # Handle potential variations in column names\n            'is laundering': 'Is Laundering',\n            'islaundering': 'Is Laundering',\n            'from account': 'From Account',\n            'fromaccount': 'From Account',\n            'to account': 'To Account',\n            'toaccount': 'To Account',\n            'payment type': 'Payment Type',\n            'paymenttype': 'Payment Type',\n            'amount paid': 'Amount Paid',\n            'amountpaid': 'Amount Paid',\n            'type account from': 'Type Account From',\n            'typeaccountfrom': 'Type Account From',\n            'type account to': 'Type Account To',\n            'typeaccountto': 'Type Account To',\n            'avg stock from': 'Avg Stock From',\n            'avgstockfrom': 'Avg Stock From',\n            'avg stock account from': 'Avg Stock From',\n            'avg stock to': 'Avg Stock To',\n            'avgstockto': 'Avg Stock To',\n            'avg stock account to': 'Avg Stock To'\n        }\n        \n        # Create mapping from current columns to standardized names\n        new_columns = {}\n        for col in df_clean.columns:\n            col_lower = col.lower().strip()\n            if col_lower in column_mappings:\n                new_columns[col] = column_mappings[col_lower]\n            else:\n                new_columns[col] = col\n        \n        df_clean.rename(columns=new_columns, inplace=True)\n        return df_clean\n        \n    def load_data(self, train_path, test_path):\n        \"\"\"Load training and test datasets\"\"\"\n        # The CSV files use space as delimiter with quoted column names\n        try:\n            # Use space as separator and handle quoted strings\n            self.train_df = pd.read_csv(train_path, sep=' ', quotechar='\"', skipinitialspace=True)\n            self.test_df = pd.read_csv(test_path, sep=' ', quotechar='\"', skipinitialspace=True)\n            \n            print(\"✓ Successfully loaded with space delimiter\")\n            \n        except Exception as e:\n            print(f\"Space delimiter failed: {e}\")\n            \n            try:\n                # Alternative approach: use whitespace regex separator\n                self.train_df = pd.read_csv(train_path, sep=r'\\s+', quotechar='\"', engine='python')\n                self.test_df = pd.read_csv(test_path, sep=r'\\s+', quotechar='\"', engine='python')\n                \n                print(\"✓ Successfully loaded with regex whitespace delimiter\")\n                \n            except Exception as e2:\n                print(f\"Regex delimiter also failed: {e2}\")\n                \n                # Manual parsing as last resort\n                print(\"Attempting manual parsing...\")\n                self.train_df = self._manual_parse_csv(train_path, has_target=True)\n                self.test_df = self._manual_parse_csv(test_path, has_target=False)\n        \n        # Clean column names by removing quotes and extra spaces\n        self.train_df.columns = self.train_df.columns.str.strip().str.replace('\"', '')\n        self.test_df.columns = self.test_df.columns.str.strip().str.replace('\"', '')\n        \n        # Standardize column names\n        self.train_df = self.standardize_column_names(self.train_df)\n        self.test_df = self.standardize_column_names(self.test_df)\n        \n        print(f\"Training set shape: {self.train_df.shape}\")\n        print(f\"Test set shape: {self.test_df.shape}\")\n        print(f\"Training columns: {list(self.train_df.columns)}\")\n        print(f\"Test columns: {list(self.test_df.columns)}\")\n        \n        return self.train_df, self.test_df\n    \n    def _manual_parse_csv(self, file_path, has_target=True):\n        \"\"\"Manual CSV parsing for space-delimited files with quoted strings\"\"\"\n        import re\n        \n        data = []\n        with open(file_path, 'r') as f:\n            lines = f.readlines()\n        \n        # Parse header\n        header_line = lines[0].strip()\n        \n        # Extract quoted column names using regex\n        column_pattern = r'\"([^\"]*)\"'\n        columns = re.findall(column_pattern, header_line)\n        \n        # If we have target column at the beginning (not quoted)\n        if has_target and not header_line.startswith('\"'):\n            # Split by space, first element is the target column\n            parts = header_line.split(' ', 1)\n            columns = [parts[0]] + re.findall(column_pattern, parts[1])\n        \n        print(f\"Parsed columns: {columns}\")\n        \n        # Parse data rows\n        for line in lines[1:]:\n            line = line.strip()\n            if not line:\n                continue\n            \n            # Parse each row\n            row_data = []\n            remaining = line\n            \n            if has_target:\n                # First element (target) is not quoted\n                parts = remaining.split(' ', 1)\n                row_data.append(int(parts[0]))\n                remaining = parts[1] if len(parts) > 1 else \"\"\n            \n            # Parse quoted and unquoted values\n            while remaining:\n                remaining = remaining.strip()\n                if not remaining:\n                    break\n                \n                if remaining.startswith('\"'):\n                    # Find the closing quote\n                    end_quote = remaining.find('\"', 1)\n                    if end_quote != -1:\n                        value = remaining[1:end_quote]\n                        row_data.append(value)\n                        remaining = remaining[end_quote + 1:].strip()\n                    else:\n                        # Quote not closed, take rest as is\n                        row_data.append(remaining[1:])\n                        break\n                else:\n                    # Find next space or quote\n                    next_space = remaining.find(' ')\n                    next_quote = remaining.find('\"')\n                    \n                    if next_space == -1 and next_quote == -1:\n                        # Last value\n                        try:\n                            row_data.append(float(remaining))\n                        except:\n                            row_data.append(remaining)\n                        break\n                    elif next_quote != -1 and (next_space == -1 or next_quote < next_space):\n                        # Next value is quoted\n                        if next_quote > 0:\n                            # There's a value before the quote\n                            try:\n                                row_data.append(float(remaining[:next_quote].strip()))\n                            except:\n                                row_data.append(remaining[:next_quote].strip())\n                        remaining = remaining[next_quote:]\n                    else:\n                        # Next value ends at space\n                        try:\n                            row_data.append(float(remaining[:next_space]))\n                        except:\n                            row_data.append(remaining[:next_space])\n                        remaining = remaining[next_space + 1:]\n            \n            if len(row_data) == len(columns):\n                data.append(row_data)\n        \n        df = pd.DataFrame(data, columns=columns)\n        print(f\"Manual parsing result: {df.shape}\")\n        return df\n    \n    def print_data_samples(self, n_samples=5):\n        \"\"\"Print sample data from train and test sets\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"TRAINING SET SAMPLES\")\n        print(\"=\"*60)\n        \n        print(f\"\\nFirst {n_samples} rows of training data:\")\n        print(self.train_df.head(n_samples))\n        \n        print(f\"\\nRandom {n_samples} rows of training data:\")\n        print(self.train_df.sample(n_samples, random_state=42))\n        \n        print(\"\\n\" + \"=\"*60)\n        print(\"TEST SET SAMPLES\") \n        print(\"=\"*60)\n        \n        print(f\"\\nFirst {n_samples} rows of test data:\")\n        print(self.test_df.head(n_samples))\n        \n        print(f\"\\nRandom {n_samples} rows of test data:\")\n        print(self.test_df.sample(n_samples, random_state=42))\n    \n    def print_data_info(self):\n        \"\"\"Print detailed information about the datasets\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"DETAILED DATA INFORMATION\")\n        print(\"=\"*60)\n        \n        print(\"\\n--- TRAINING SET INFO ---\")\n        print(f\"Shape: {self.train_df.shape}\")\n        print(f\"Memory usage: {self.train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n        print(\"\\nData types:\")\n        print(self.train_df.dtypes)\n        print(\"\\nNull values:\")\n        print(self.train_df.isnull().sum())\n        \n        print(\"\\n--- TEST SET INFO ---\")\n        print(f\"Shape: {self.test_df.shape}\")\n        print(f\"Memory usage: {self.test_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n        print(\"\\nData types:\")\n        print(self.test_df.dtypes)\n        print(\"\\nNull values:\")\n        print(self.test_df.isnull().sum())\n    \n    def print_statistical_summary(self):\n        \"\"\"Print statistical summary of numerical columns\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"STATISTICAL SUMMARY\")\n        print(\"=\"*60)\n        \n        print(\"\\n--- TRAINING SET STATISTICS ---\")\n        print(self.train_df.describe())\n        \n        print(\"\\n--- TEST SET STATISTICS ---\")\n        print(self.test_df.describe())\n        \n        # Additional statistics for key columns\n        if 'Amount Paid' in self.train_df.columns:\n            print(f\"\\n--- AMOUNT PAID ANALYSIS ---\")\n            print(f\"Training - Min: {self.train_df['Amount Paid'].min():,.2f}\")\n            print(f\"Training - Max: {self.train_df['Amount Paid'].max():,.2f}\")\n            print(f\"Training - Median: {self.train_df['Amount Paid'].median():,.2f}\")\n            print(f\"Training - Mean: {self.train_df['Amount Paid'].mean():,.2f}\")\n            \n            print(f\"Test - Min: {self.test_df['Amount Paid'].min():,.2f}\")\n            print(f\"Test - Max: {self.test_df['Amount Paid'].max():,.2f}\")\n            print(f\"Test - Median: {self.test_df['Amount Paid'].median():,.2f}\")\n            print(f\"Test - Mean: {self.test_df['Amount Paid'].mean():,.2f}\")\n    \n    def print_categorical_analysis(self):\n        \"\"\"Print analysis of categorical columns\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"CATEGORICAL VARIABLES ANALYSIS\")\n        print(\"=\"*60)\n        \n        categorical_cols = ['Payment Type', 'Type Account From', 'Type Account To']\n        \n        for col in categorical_cols:\n            if col in self.train_df.columns:\n                print(f\"\\n--- {col.upper()} DISTRIBUTION ---\")\n                print(\"Training set:\")\n                train_counts = self.train_df[col].value_counts()\n                train_pct = self.train_df[col].value_counts(normalize=True) * 100\n                for idx in train_counts.index:\n                    print(f\"  {idx}: {train_counts[idx]:,} ({train_pct[idx]:.1f}%)\")\n                \n                print(\"Test set:\")\n                test_counts = self.test_df[col].value_counts()\n                test_pct = self.test_df[col].value_counts(normalize=True) * 100\n                for idx in test_counts.index:\n                    print(f\"  {idx}: {test_counts[idx]:,} ({test_pct[idx]:.1f}%)\")\n    \n    def print_target_analysis(self):\n        \"\"\"Print target variable analysis (only for training set)\"\"\"\n        if 'Is Laundering' not in self.train_df.columns:\n            print(\"Target variable 'Is Laundering' not found in training set\")\n            return\n            \n        print(\"\\n\" + \"=\"*60)\n        print(\"TARGET VARIABLE ANALYSIS\")\n        print(\"=\"*60)\n        \n        target_counts = self.train_df['Is Laundering'].value_counts()\n        target_pct = self.train_df['Is Laundering'].value_counts(normalize=True) * 100\n        \n        print(f\"Non-laundering (0): {target_counts[0]:,} ({target_pct[0]:.2f}%)\")\n        print(f\"Laundering (1): {target_counts[1]:,} ({target_pct[1]:.2f}%)\")\n        print(f\"Class imbalance ratio: {target_counts[0]/target_counts[1]:.1f}:1\")\n        \n        # Laundering patterns by categorical variables\n        categorical_cols = ['Payment Type', 'Type Account From', 'Type Account To']\n        \n        for col in categorical_cols:\n            if col in self.train_df.columns:\n                print(f\"\\n--- LAUNDERING RATE BY {col.upper()} ---\")\n                laundering_by_cat = self.train_df.groupby(col)['Is Laundering'].agg(['count', 'sum', 'mean'])\n                laundering_by_cat.columns = ['Total', 'Laundering_Count', 'Laundering_Rate']\n                laundering_by_cat['Laundering_Rate'] = laundering_by_cat['Laundering_Rate'] * 100\n                laundering_by_cat = laundering_by_cat.sort_values('Laundering_Rate', ascending=False)\n                \n                for idx, row in laundering_by_cat.iterrows():\n                    print(f\"  {idx}: {row['Laundering_Count']}/{row['Total']} ({row['Laundering_Rate']:.2f}%)\")\n    \n    def print_account_analysis(self):\n        \"\"\"Print account-level analysis\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"ACCOUNT ANALYSIS\")\n        print(\"=\"*60)\n        \n        # Unique accounts\n        if 'From Account' in self.train_df.columns and 'To Account' in self.train_df.columns:\n            train_from_accounts = set(self.train_df['From Account'].unique())\n            train_to_accounts = set(self.train_df['To Account'].unique())\n            test_from_accounts = set(self.test_df['From Account'].unique())\n            test_to_accounts = set(self.test_df['To Account'].unique())\n            \n            all_train_accounts = train_from_accounts.union(train_to_accounts)\n            all_test_accounts = test_from_accounts.union(test_to_accounts)\n            \n            print(f\"Unique 'From' accounts in training: {len(train_from_accounts):,}\")\n            print(f\"Unique 'To' accounts in training: {len(train_to_accounts):,}\")\n            print(f\"Total unique accounts in training: {len(all_train_accounts):,}\")\n            \n            print(f\"Unique 'From' accounts in test: {len(test_from_accounts):,}\")\n            print(f\"Unique 'To' accounts in test: {len(test_to_accounts):,}\")\n            print(f\"Total unique accounts in test: {len(all_test_accounts):,}\")\n            \n            # Account overlap\n            overlapping_accounts = all_train_accounts.intersection(all_test_accounts)\n            print(f\"Accounts appearing in both train and test: {len(overlapping_accounts):,}\")\n            print(f\"Account overlap percentage: {len(overlapping_accounts)/len(all_train_accounts)*100:.1f}%\")\n            \n            # Most active accounts\n            print(f\"\\n--- MOST ACTIVE SENDER ACCOUNTS (TRAINING) ---\")\n            from_activity = self.train_df['From Account'].value_counts().head(10)\n            for account, count in from_activity.items():\n                print(f\"  {account}: {count:,} transactions\")\n            \n            print(f\"\\n--- MOST ACTIVE RECEIVER ACCOUNTS (TRAINING) ---\")\n            to_activity = self.train_df['To Account'].value_counts().head(10)\n            for account, count in to_activity.items():\n                print(f\"  {account}: {count:,} transactions\")\n    \n    def handle_missing_values(self, df):\n        \"\"\"Handle missing values with domain-specific logic\"\"\"\n        df_clean = df.copy()\n        \n        # For financial data, missing average stock might indicate new accounts\n        # Fill with 0 or median based on account type\n        for col in ['Avg Stock From', 'Avg Stock To']:\n            if col in df_clean.columns:\n                # Fill missing values with median for each account type\n                for acc_type in ['Type Account From', 'Type Account To']:\n                    if acc_type in df_clean.columns:\n                        type_col = acc_type.replace('Type ', '').replace(' From', '').replace(' To', '')\n                        df_clean[col] = df_clean.groupby(acc_type)[col].transform(\n                            lambda x: x.fillna(x.median())\n                        )\n                \n                # Fill remaining NaN with overall median\n                df_clean[col].fillna(df_clean[col].median(), inplace=True)\n        \n        # Handle categorical missing values\n        categorical_cols = ['Payment Type', 'Type Account From', 'Type Account To']\n        for col in categorical_cols:\n            if col in df_clean.columns:\n                df_clean[col].fillna('Unknown', inplace=True)\n        \n        return df_clean\n    \n    def create_account_features(self, df):\n        \"\"\"Create account-level aggregated features\"\"\"\n        df_enhanced = df.copy()\n        \n        # Account activity features\n        account_stats = {}\n        \n        # From Account features\n        from_stats = df.groupby('From Account').agg({\n            'Amount Paid': ['count', 'sum', 'mean', 'std', 'min', 'max'],\n            'Payment Type': lambda x: len(x.unique()),\n            'To Account': lambda x: len(x.unique())  # Number of unique recipients\n        }).reset_index()\n        \n        from_stats.columns = ['From Account', 'from_tx_count', 'from_total_amount', \n                             'from_avg_amount', 'from_std_amount', 'from_min_amount', \n                             'from_max_amount', 'from_payment_types', 'from_unique_recipients']\n        \n        # To Account features\n        to_stats = df.groupby('To Account').agg({\n            'Amount Paid': ['count', 'sum', 'mean', 'std', 'min', 'max'],\n            'Payment Type': lambda x: len(x.unique()),\n            'From Account': lambda x: len(x.unique())  # Number of unique senders\n        }).reset_index()\n        \n        to_stats.columns = ['To Account', 'to_tx_count', 'to_total_amount', \n                           'to_avg_amount', 'to_std_amount', 'to_min_amount', \n                           'to_max_amount', 'to_payment_types', 'to_unique_senders']\n        \n        # Merge account features\n        df_enhanced = df_enhanced.merge(from_stats, on='From Account', how='left')\n        df_enhanced = df_enhanced.merge(to_stats, on='To Account', how='left')\n        \n        # Fill NaN values for new accounts in test set\n        account_feature_cols = [col for col in df_enhanced.columns if col.startswith(('from_', 'to_'))]\n        for col in account_feature_cols:\n            df_enhanced[col].fillna(0, inplace=True)\n        \n        return df_enhanced\n    \n    def create_network_features(self, df):\n        \"\"\"Create network-based features to detect coordinated operations\"\"\"\n        df_network = df.copy()\n        \n        # Create transaction network\n        G = nx.from_pandas_edgelist(df, source='From Account', target='To Account', \n                                   edge_attr=['Amount Paid', 'Payment Type'], \n                                   create_using=nx.DiGraph())\n        \n        # Calculate network centrality measures\n        try:\n            in_degree_centrality = nx.in_degree_centrality(G)\n            out_degree_centrality = nx.out_degree_centrality(G)\n            betweenness_centrality = nx.betweenness_centrality(G, k=min(1000, len(G.nodes())))\n            \n            # Map centrality measures back to transactions\n            df_network['from_out_degree_centrality'] = df_network['From Account'].map(out_degree_centrality).fillna(0)\n            df_network['from_betweenness_centrality'] = df_network['From Account'].map(betweenness_centrality).fillna(0)\n            df_network['to_in_degree_centrality'] = df_network['To Account'].map(in_degree_centrality).fillna(0)\n            df_network['to_betweenness_centrality'] = df_network['To Account'].map(betweenness_centrality).fillna(0)\n            \n        except Exception as e:\n            print(f\"Network analysis warning: {e}\")\n            # Create dummy features if network analysis fails\n            df_network['from_out_degree_centrality'] = 0\n            df_network['from_betweenness_centrality'] = 0\n            df_network['to_in_degree_centrality'] = 0\n            df_network['to_betweenness_centrality'] = 0\n        \n        # Detect potential circular transactions (A->B->A patterns)\n        account_pairs = df.groupby(['From Account', 'To Account']).size().reset_index(name='pair_frequency')\n        reverse_pairs = account_pairs.copy()\n        reverse_pairs.columns = ['To Account', 'From Account', 'reverse_pair_frequency']\n        \n        df_network = df_network.merge(account_pairs, on=['From Account', 'To Account'], how='left')\n        df_network = df_network.merge(reverse_pairs, on=['From Account', 'To Account'], how='left')\n        df_network['pair_frequency'].fillna(1, inplace=True)\n        df_network['reverse_pair_frequency'].fillna(0, inplace=True)\n        \n        # Flag potential circular transactions\n        df_network['is_circular'] = (df_network['reverse_pair_frequency'] > 0).astype(int)\n        \n        return df_network\n    \n    def create_behavioral_features(self, df):\n        \"\"\"Create behavioral and temporal features\"\"\"\n        df_behavioral = df.copy()\n        \n        # Amount-based features\n        df_behavioral['amount_to_avg_stock_from_ratio'] = (\n            df_behavioral['Amount Paid'] / (df_behavioral['Avg Stock From'] + 1)\n        )\n        df_behavioral['amount_to_avg_stock_to_ratio'] = (\n            df_behavioral['Amount Paid'] / (df_behavioral['Avg Stock To'] + 1)\n        )\n        \n        # Account balance disparity\n        df_behavioral['stock_balance_diff'] = (\n            df_behavioral['Avg Stock From'] - df_behavioral['Avg Stock To']\n        )\n        df_behavioral['stock_balance_ratio'] = (\n            df_behavioral['Avg Stock From'] / (df_behavioral['Avg Stock To'] + 1)\n        )\n        \n        # Round number detection (common in money laundering)\n        df_behavioral['is_round_amount'] = (df_behavioral['Amount Paid'] % 100 == 0).astype(int)\n        df_behavioral['is_very_round_amount'] = (df_behavioral['Amount Paid'] % 1000 == 0).astype(int)\n        \n        # Account type mismatch features\n        df_behavioral['account_type_match'] = (\n            df_behavioral['Type Account From'] == df_behavioral['Type Account To']\n        ).astype(int)\n        \n        # Create account type interaction features\n        df_behavioral['account_type_interaction'] = (\n            df_behavioral['Type Account From'] + '_to_' + df_behavioral['Type Account To']\n        )\n        \n        return df_behavioral\n    \n    def encode_categorical_features(self, df, fit=True):\n        \"\"\"Encode categorical features\"\"\"\n        df_encoded = df.copy()\n        \n        categorical_features = ['Payment Type', 'Type Account From', 'Type Account To', 'account_type_interaction']\n        \n        for feature in categorical_features:\n            if feature in df_encoded.columns:\n                if fit:\n                    self.label_encoders[feature] = LabelEncoder()\n                    df_encoded[feature] = self.label_encoders[feature].fit_transform(df_encoded[feature].astype(str))\n                else:\n                    if feature in self.label_encoders:\n                        # Handle unseen categories in test set\n                        known_categories = set(self.label_encoders[feature].classes_)\n                        df_encoded[feature] = df_encoded[feature].astype(str)\n                        df_encoded[feature] = df_encoded[feature].apply(\n                            lambda x: x if x in known_categories else 'Unknown'\n                        )\n                        \n                        # Add 'Unknown' to encoder if not present\n                        if 'Unknown' not in known_categories:\n                            self.label_encoders[feature].classes_ = np.append(\n                                self.label_encoders[feature].classes_, 'Unknown'\n                            )\n                        \n                        df_encoded[feature] = self.label_encoders[feature].transform(df_encoded[feature])\n        \n        return df_encoded\n    \n    def scale_numerical_features(self, df, fit=True):\n        \"\"\"Scale numerical features using RobustScaler (less sensitive to outliers)\"\"\"\n        df_scaled = df.copy()\n        \n        # Identify numerical features (excluding target and IDs)\n        numerical_features = df_scaled.select_dtypes(include=[np.number]).columns.tolist()\n        \n        # Remove target variable and account IDs if present\n        exclude_cols = ['Is Laundering', 'From Account', 'To Account']\n        numerical_features = [col for col in numerical_features if col not in exclude_cols]\n        \n        if fit:\n            self.scalers['numerical'] = RobustScaler()\n            df_scaled[numerical_features] = self.scalers['numerical'].fit_transform(df_scaled[numerical_features])\n        else:\n            if 'numerical' in self.scalers:\n                df_scaled[numerical_features] = self.scalers['numerical'].transform(df_scaled[numerical_features])\n        \n        return df_scaled\n    \n    def create_feature_interactions(self, df):\n        \"\"\"Create important feature interactions\"\"\"\n        df_interactions = df.copy()\n        \n        # Amount and account type interactions\n        for acc_type in ['Type Account From', 'Type Account To']:\n            if acc_type in df_interactions.columns:\n                interaction_col = f'amount_x_{acc_type.lower().replace(\" \", \"_\")}'\n                df_interactions[interaction_col] = (\n                    df_interactions['Amount Paid'] * df_interactions[acc_type]\n                )\n        \n        # Payment type and amount interactions\n        if 'Payment Type' in df_interactions.columns:\n            df_interactions['amount_x_payment_type'] = (\n                df_interactions['Amount Paid'] * df_interactions['Payment Type']\n            )\n        \n        return df_interactions\n    \n    def fit_transform(self, train_df):\n        \"\"\"Fit the preprocessor on training data and transform it\"\"\"\n        print(\"\\n=== FITTING PREPROCESSOR ON TRAINING DATA ===\")\n        \n        # Step 1: Handle missing values\n        print(\"1. Handling missing values...\")\n        train_clean = self.handle_missing_values(train_df)\n        \n        # Step 2: Create account-level features\n        print(\"2. Creating account-level features...\")\n        train_account = self.create_account_features(train_clean)\n        \n        # Step 3: Create network features\n        print(\"3. Creating network features...\")\n        train_network = self.create_network_features(train_account)\n        \n        # Step 4: Create behavioral features\n        print(\"4. Creating behavioral features...\")\n        train_behavioral = self.create_behavioral_features(train_network)\n        \n        # Step 5: Encode categorical features\n        print(\"5. Encoding categorical features...\")\n        train_encoded = self.encode_categorical_features(train_behavioral, fit=True)\n        \n        # Step 6: Create feature interactions\n        print(\"6. Creating feature interactions...\")\n        train_interactions = self.create_feature_interactions(train_encoded)\n        \n        # Step 7: Scale numerical features\n        print(\"7. Scaling numerical features...\")\n        train_final = self.scale_numerical_features(train_interactions, fit=True)\n        \n        self.fitted = True\n        print(\"✓ Preprocessor fitted successfully!\")\n        \n        return train_final\n    \n    def transform(self, test_df):\n        \"\"\"Transform test data using fitted preprocessor\"\"\"\n        if not self.fitted:\n            raise ValueError(\"Preprocessor must be fitted before transforming test data\")\n        \n        print(\"\\n=== TRANSFORMING TEST DATA ===\")\n        \n        # Apply same transformation pipeline\n        test_clean = self.handle_missing_values(test_df)\n        test_account = self.create_account_features(test_clean)\n        test_network = self.create_network_features(test_account)\n        test_behavioral = self.create_behavioral_features(test_network)\n        test_encoded = self.encode_categorical_features(test_behavioral, fit=False)\n        test_interactions = self.create_feature_interactions(test_encoded)\n        test_final = self.scale_numerical_features(test_interactions, fit=False)\n        \n        print(\"✓ Test data transformed successfully!\")\n        \n        return test_final\n    \n    def get_feature_names(self, df):\n        \"\"\"Get list of feature names (excluding target and IDs)\"\"\"\n        exclude_cols = ['Is Laundering', 'From Account', 'To Account']\n        feature_names = [col for col in df.columns if col not in exclude_cols]\n        return feature_names\n\n# Usage example with debugging:\ndef main():\n    # Initialize preprocessor\n    preprocessor = MoneyLaunderingPreprocessor()\n    \n    # Debug CSV loading\n    def debug_csv_structure(file_path):\n        \"\"\"Debug function to understand CSV structure\"\"\"\n        print(f\"\\n=== DEBUGGING CSV STRUCTURE: {file_path} ===\")\n        \n        # Read first few lines as text\n        with open(file_path, 'r') as f:\n            for i, line in enumerate(f):\n                if i < 3:  # Show first 3 lines\n                    print(f\"Line {i+1}: {repr(line[:200])}\")  # Show first 200 chars\n                else:\n                    break\n        \n        # Try different pandas read options\n        try:\n            df1 = pd.read_csv(file_path, nrows=5)\n            print(f\"Default read - Shape: {df1.shape}, Columns: {list(df1.columns)}\")\n        except Exception as e:\n            print(f\"Default read failed: {e}\")\n        \n        try:\n            df2 = pd.read_csv(file_path, nrows=5, quotechar='\"')\n            print(f\"With quotechar - Shape: {df2.shape}, Columns: {list(df2.columns)}\")\n        except Exception as e:\n            print(f\"Quotechar read failed: {e}\")\n            \n        try:\n            df3 = pd.read_csv(file_path, nrows=5, sep=',', quoting=1)\n            print(f\"With quoting=1 - Shape: {df3.shape}, Columns: {list(df3.columns)}\")\n        except Exception as e:\n            print(f\"Quoting=1 read failed: {e}\")\n    \n    # Debug both files\n    try:\n        debug_csv_structure('/kaggle/input/statsunderstars/Dataset/train.csv')\n        debug_csv_structure('/kaggle/input/statsunderstars/Dataset/test.csv')\n    except:\n        # If debug files don't exist, try the original names\n        debug_csv_structure('sus8_train.csv')\n        debug_csv_structure('sus8_test.csv')\n    \n    # Load data with correct file paths\n    try:\n        train_df, test_df = preprocessor.load_data('/kaggle/input/statsunderstars/Dataset/train.csv', \n                                                 '/kaggle/input/statsunderstars/Dataset/test.csv')\n    except:\n        # Fallback to original names\n        train_df, test_df = preprocessor.load_data('sus8_train.csv', 'sus8_test.csv')\n    \n    # If still having issues, stop here for debugging\n    if train_df.shape[1] <= 2:\n        print(\"\\n❌ CSV parsing issue detected. Please check the debug output above.\")\n        print(\"The CSV files might have a different format than expected.\")\n        return None, None, None, None, None\n    \n    # Print comprehensive data exploration\n    print(\"\\n🔍 EXPLORING LOADED DATA...\")\n    \n    # Basic samples\n    preprocessor.print_data_samples(n_samples=3)\n    \n    # Detailed information\n    preprocessor.print_data_info()\n    \n    # Statistical summaries\n    preprocessor.print_statistical_summary()\n    \n    # Categorical analysis\n    preprocessor.print_categorical_analysis()\n    \n    # Target analysis\n    preprocessor.print_target_analysis()\n    \n    # Account analysis\n    preprocessor.print_account_analysis()\n    \n    # Ask user if they want to continue with preprocessing\n    print(f\"\\n{'='*60}\")\n    print(\"DATA EXPLORATION COMPLETE\")\n    print(f\"{'='*60}\")\n    print(\"\\nReady to proceed with preprocessing...\")\n    \n    # Continue with preprocessing\n    train_processed = preprocessor.fit_transform(train_df)\n    \n    # Preprocess test data\n    test_processed = preprocessor.transform(test_df)\n    \n    # Get feature names\n    feature_names = preprocessor.get_feature_names(train_processed)\n    \n    print(f\"\\n=== PREPROCESSING COMPLETE ===\")\n    print(f\"Original training features: {len(train_df.columns)}\")\n    print(f\"Processed training features: {len(feature_names)}\")\n    print(f\"Training set shape: {train_processed.shape}\")\n    print(f\"Test set shape: {test_processed.shape}\")\n    \n    # Prepare final datasets\n    X_train = train_processed[feature_names]\n    y_train = train_processed['Is Laundering'] if 'Is Laundering' in train_processed.columns else None\n    X_test = test_processed[feature_names]\n    \n    return X_train, y_train, X_test, feature_names, preprocessor\n\nif __name__ == \"__main__\":\n    X_train, y_train, X_test, feature_names, preprocessor = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:24:30.588738Z","iopub.execute_input":"2025-06-16T00:24:30.589236Z","iopub.status.idle":"2025-06-16T00:25:51.648664Z","shell.execute_reply.started":"2025-06-16T00:24:30.589212Z","shell.execute_reply":"2025-06-16T00:25:51.647964Z"}},"outputs":[{"name":"stdout","text":"\n=== DEBUGGING CSV STRUCTURE: /kaggle/input/statsunderstars/Dataset/train.csv ===\nLine 1: '\"Is Laundering\" \"From Account\" \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"\\n'\nLine 2: '1 \"U0551\" \"U2203\" \"Cheque\" 186509.285 \"B\" \"B\" 308533361.047 1144577.897\\n'\nLine 3: '0 \"U4572\" \"U9001\" \"ACH\" 439.995 \"D\" \"B\" 37526.141 2084650.425\\n'\nDefault read - Shape: (5, 1), Columns: ['Is Laundering \"From Account\" \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\nWith quotechar - Shape: (5, 1), Columns: ['Is Laundering \"From Account\" \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\nWith quoting=1 - Shape: (5, 1), Columns: ['Is Laundering \"From Account\" \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\n\n=== DEBUGGING CSV STRUCTURE: /kaggle/input/statsunderstars/Dataset/test.csv ===\nLine 1: '\"From Account\" \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"\\n'\nLine 2: '\"U7751\" \"U9254\" \"Cheque\" 1097.343 \"C\" \"B\" 9637.145 2893306.8\\n'\nLine 3: '\"U7875\" \"U9283\" \"Credit Card\" 468.615 \"F\" \"B\" 6791.753 4302009.02\\n'\nDefault read - Shape: (5, 1), Columns: ['From Account \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\nWith quotechar - Shape: (5, 1), Columns: ['From Account \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\nWith quoting=1 - Shape: (5, 1), Columns: ['From Account \"To Account\" \"Payment Type\" \"Amount Paid\" \"Type Account From\" \"Type Account To\" \"Avg Stock Account From\" \"Avg Stock Account To\"']\n✓ Successfully loaded with space delimiter\nTraining set shape: (55307, 9)\nTest set shape: (23743, 8)\nTraining columns: ['Is Laundering', 'From Account', 'To Account', 'Payment Type', 'Amount Paid', 'Type Account From', 'Type Account To', 'Avg Stock From', 'Avg Stock To']\nTest columns: ['From Account', 'To Account', 'Payment Type', 'Amount Paid', 'Type Account From', 'Type Account To', 'Avg Stock From', 'Avg Stock To']\n\n🔍 EXPLORING LOADED DATA...\n\n============================================================\nTRAINING SET SAMPLES\n============================================================\n\nFirst 3 rows of training data:\n   Is Laundering From Account To Account Payment Type  Amount Paid  \\\n0              1        U0551      U2203       Cheque   186509.285   \n1              0        U4572      U9001          ACH      439.995   \n2              1        U0551      U2203       Cheque   186711.187   \n\n  Type Account From Type Account To  Avg Stock From  Avg Stock To  \n0                 B               B    3.085334e+08   1144577.897  \n1                 D               B    3.752614e+04   2084650.425  \n2                 E               B    3.085329e+08   1144922.015  \n\nRandom 3 rows of training data:\n       Is Laundering From Account To Account Payment Type  Amount Paid  \\\n49950              0       U05548     U06612       Cheque     5208.867   \n23920              0       U05557     U14970       Cheque    12334.090   \n30927              0       U00003     U00542          ACH     1687.733   \n\n      Type Account From Type Account To  Avg Stock From  Avg Stock To  \n49950                 B               F     1158603.268   6390198.999  \n23920                 E               D       59245.987   1043357.899  \n30927                 C               D     2058000.289    357680.312  \n\n============================================================\nTEST SET SAMPLES\n============================================================\n\nFirst 3 rows of test data:\n  From Account To Account Payment Type  Amount Paid Type Account From  \\\n0        U7751      U9254       Cheque     1097.343                 C   \n1        U7875      U9283  Credit Card      468.615                 F   \n2        U8381      U8381          ACH        0.680                 B   \n\n  Type Account To  Avg Stock From  Avg Stock To  \n0               B        9637.145   2893306.800  \n1               B        6791.753   4302009.020  \n2               B         275.427      1673.652  \n\nRandom 3 rows of test data:\n      From Account To Account Payment Type  Amount Paid Type Account From  \\\n16424       U00451     U13068       Cheque  1013389.110                 A   \n13687       U18156     U14776       Cheque     1652.013                 B   \n18231       U21163     U00613       Cheque    54250.234                 B   \n\n      Type Account To  Avg Stock From  Avg Stock To  \n16424               D     7096409.933  1.311591e+06  \n13687               A       12159.342  1.775568e+04  \n18231               E      381550.586  1.371763e+07  \n\n============================================================\nDETAILED DATA INFORMATION\n============================================================\n\n--- TRAINING SET INFO ---\nShape: (55307, 9)\nMemory usage: 17.79 MB\n\nData types:\nIs Laundering          int64\nFrom Account          object\nTo Account            object\nPayment Type          object\nAmount Paid          float64\nType Account From     object\nType Account To       object\nAvg Stock From       float64\nAvg Stock To         float64\ndtype: object\n\nNull values:\nIs Laundering        0\nFrom Account         0\nTo Account           0\nPayment Type         0\nAmount Paid          0\nType Account From    0\nType Account To      0\nAvg Stock From       0\nAvg Stock To         0\ndtype: int64\n\n--- TEST SET INFO ---\nShape: (23743, 8)\nMemory usage: 7.46 MB\n\nData types:\nFrom Account          object\nTo Account            object\nPayment Type          object\nAmount Paid          float64\nType Account From     object\nType Account To       object\nAvg Stock From       float64\nAvg Stock To         float64\ndtype: object\n\nNull values:\nFrom Account         0\nTo Account           0\nPayment Type         0\nAmount Paid          0\nType Account From    0\nType Account To      0\nAvg Stock From       0\nAvg Stock To         0\ndtype: int64\n\n============================================================\nSTATISTICAL SUMMARY\n============================================================\n\n--- TRAINING SET STATISTICS ---\n       Is Laundering   Amount Paid  Avg Stock From  Avg Stock To\ncount   55307.000000  5.530700e+04    5.530700e+04  5.530700e+04\nmean        0.012403  1.010106e+08    7.071408e+08  2.770064e+08\nstd         0.110679  1.387341e+10    9.582880e+10  1.291450e+10\nmin         0.000000  1.000000e-02    4.582000e+00  1.420700e+01\n25%         0.000000  1.100697e+03    6.581124e+04  4.421861e+04\n50%         0.000000  4.393293e+03    5.857207e+05  6.495881e+05\n75%         0.000000  6.944967e+04    4.257518e+06  3.519056e+06\nmax         1.000000  3.185472e+12    2.229830e+13  1.322178e+12\n\n--- TEST SET STATISTICS ---\n        Amount Paid  Avg Stock From  Avg Stock To\ncount  2.374300e+04    2.374300e+04  2.374300e+04\nmean   4.644958e+07    3.251446e+08  1.601221e+08\nstd    2.769298e+09    1.386380e+10  6.164153e+09\nmin    1.000000e-02    1.581700e+01  7.395000e+00\n25%    1.107820e+03    2.274724e+04  3.532536e+04\n50%    4.326599e+03    2.047596e+05  1.219325e+06\n75%    6.282238e+04    2.211340e+06  3.421184e+06\nmax    3.517245e+11    1.491280e+12  8.207005e+11\n\n--- AMOUNT PAID ANALYSIS ---\nTraining - Min: 0.01\nTraining - Max: 3,185,471,961,351.40\nTraining - Median: 4,393.29\nTraining - Mean: 101,010,619.33\nTest - Min: 0.01\nTest - Max: 351,724,510,464.76\nTest - Median: 4,326.60\nTest - Mean: 46,449,577.62\n\n============================================================\nCATEGORICAL VARIABLES ANALYSIS\n============================================================\n\n--- PAYMENT TYPE DISTRIBUTION ---\nTraining set:\n  Cheque: 31,344 (56.7%)\n  ACH: 11,102 (20.1%)\n  Credit Card: 10,995 (19.9%)\n  Cash: 1,234 (2.2%)\n  Wire: 632 (1.1%)\nTest set:\n  Cheque: 13,471 (56.7%)\n  Credit Card: 4,753 (20.0%)\n  ACH: 4,719 (19.9%)\n  Cash: 525 (2.2%)\n  Wire: 275 (1.2%)\n\n--- TYPE ACCOUNT FROM DISTRIBUTION ---\nTraining set:\n  B: 16,509 (29.8%)\n  A: 11,320 (20.5%)\n  E: 10,994 (19.9%)\n  C: 5,659 (10.2%)\n  F: 5,504 (10.0%)\n  D: 5,321 (9.6%)\nTest set:\n  B: 7,022 (29.6%)\n  A: 4,844 (20.4%)\n  E: 4,712 (19.8%)\n  C: 2,422 (10.2%)\n  D: 2,395 (10.1%)\n  F: 2,348 (9.9%)\n\n--- TYPE ACCOUNT TO DISTRIBUTION ---\nTraining set:\n  B: 15,853 (28.7%)\n  E: 11,251 (20.3%)\n  A: 10,505 (19.0%)\n  D: 6,550 (11.8%)\n  C: 5,947 (10.8%)\n  F: 5,201 (9.4%)\nTest set:\n  B: 6,369 (26.8%)\n  E: 4,441 (18.7%)\n  A: 3,947 (16.6%)\n  D: 3,781 (15.9%)\n  C: 3,212 (13.5%)\n  F: 1,993 (8.4%)\n\n============================================================\nTARGET VARIABLE ANALYSIS\n============================================================\nNon-laundering (0): 54,621 (98.76%)\nLaundering (1): 686 (1.24%)\nClass imbalance ratio: 79.6:1\n\n--- LAUNDERING RATE BY PAYMENT TYPE ---\n  ACH: 406.0/11102.0 (3.66%)\n  Cash: 17.0/1234.0 (1.38%)\n  Wire: 8.0/632.0 (1.27%)\n  Credit Card: 74.0/10995.0 (0.67%)\n  Cheque: 181.0/31344.0 (0.58%)\n\n--- LAUNDERING RATE BY TYPE ACCOUNT FROM ---\n  D: 74.0/5321.0 (1.39%)\n  B: 213.0/16509.0 (1.29%)\n  E: 141.0/10994.0 (1.28%)\n  A: 137.0/11320.0 (1.21%)\n  F: 60.0/5504.0 (1.09%)\n  C: 61.0/5659.0 (1.08%)\n\n--- LAUNDERING RATE BY TYPE ACCOUNT TO ---\n  D: 129.0/6550.0 (1.97%)\n  F: 75.0/5201.0 (1.44%)\n  B: 207.0/15853.0 (1.31%)\n  C: 72.0/5947.0 (1.21%)\n  E: 122.0/11251.0 (1.08%)\n  A: 81.0/10505.0 (0.77%)\n\n============================================================\nACCOUNT ANALYSIS\n============================================================\nUnique 'From' accounts in training: 16,998\nUnique 'To' accounts in training: 14,042\nTotal unique accounts in training: 18,844\nUnique 'From' accounts in test: 11,463\nUnique 'To' accounts in test: 11,020\nTotal unique accounts in test: 15,183\nAccounts appearing in both train and test: 13,927\nAccount overlap percentage: 73.9%\n\n--- MOST ACTIVE SENDER ACCOUNTS (TRAINING) ---\n  U00629: 1,087 transactions\n  U00560: 923 transactions\n  U00464: 738 transactions\n  U04494: 30 transactions\n  U00616: 29 transactions\n  U02204: 29 transactions\n  U00100: 29 transactions\n  U01721: 27 transactions\n  U03302: 26 transactions\n  U00624: 25 transactions\n\n--- MOST ACTIVE RECEIVER ACCOUNTS (TRAINING) ---\n  U00560: 65 transactions\n  U11636: 63 transactions\n  U05954: 59 transactions\n  U05060: 56 transactions\n  U06316: 55 transactions\n  U00629: 55 transactions\n  U01171: 54 transactions\n  U01224: 51 transactions\n  U04361: 50 transactions\n  U00307: 49 transactions\n\n============================================================\nDATA EXPLORATION COMPLETE\n============================================================\n\nReady to proceed with preprocessing...\n\n=== FITTING PREPROCESSOR ON TRAINING DATA ===\n1. Handling missing values...\n2. Creating account-level features...\n3. Creating network features...\n4. Creating behavioral features...\n5. Encoding categorical features...\n6. Creating feature interactions...\n7. Scaling numerical features...\n✓ Preprocessor fitted successfully!\n\n=== TRANSFORMING TEST DATA ===\n✓ Test data transformed successfully!\n\n=== PREPROCESSING COMPLETE ===\nOriginal training features: 9\nProcessed training features: 40\nTraining set shape: (55307, 43)\nTest set shape: (23743, 42)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, balanced_accuracy_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.utils import resample\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\n\n\n# Custom metrics implementation\ndef calculate_balanced_accuracy(y_true, y_pred):\n    \"\"\"Calculate balanced accuracy: average of TPR and TNR\"\"\"\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    \n    # True Positive Rate (Sensitivity/Recall)\n    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n    \n    # True Negative Rate (Specificity)\n    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n    \n    balanced_acc = (tpr + tnr) / 2\n    return balanced_acc\n\ndef calculate_fraud_capture_rate(y_true, y_prob, N=485):\n    \"\"\"Calculate fraud capture rate for top N predictions\"\"\"\n    # Get indices sorted by probability (highest first)\n    sorted_indices = np.argsort(y_prob)[::-1]\n    \n    # Get top N indices\n    top_N_indices = sorted_indices[:N]\n    \n    # Count frauds in top N predictions\n    frauds_in_top_N = np.sum(y_true.iloc[top_N_indices] if hasattr(y_true, 'iloc') else y_true[top_N_indices])\n    \n    # Total number of frauds in dataset\n    total_frauds = np.sum(y_true)\n    \n    # Fraud capture rate\n    fraud_capture_rate = frauds_in_top_N / total_frauds if total_frauds > 0 else 0\n    \n    return fraud_capture_rate\n\ndef calculate_composite_score(y_true, y_pred, y_prob, N=485):\n    \"\"\"Calculate the composite score as arithmetic mean of AUC, Balanced Accuracy, and Fraud Capture Rate\"\"\"\n    \n    # 1. AUC (Area Under the Curve)\n    auc_score = roc_auc_score(y_true, y_prob)\n    \n    # 2. Balanced Accuracy\n    balanced_acc = calculate_balanced_accuracy(y_true, y_pred)\n    \n    # 3. Fraud Capture Rate (Top N predictions)\n    fraud_capture = calculate_fraud_capture_rate(y_true, y_prob, N)\n    \n    # Final composite score (arithmetic mean)\n    composite_score = (auc_score + balanced_acc + fraud_capture) / 3\n    \n    return {\n        'auc': auc_score,\n        'balanced_accuracy': balanced_acc,\n        'fraud_capture_rate': fraud_capture,\n        'composite_score': composite_score\n    }\n\nclass MoneyLaunderingModelTrainer:\n    def __init__(self):\n        self.models = {}\n        self.model_scores = {}\n        self.best_model = None\n        self.feature_importance = None\n        self.N = 485  # Top N predictions for fraud capture rate\n        \n    def handle_class_imbalance(self, X_train, y_train, method='smote'):\n        \"\"\"Handle severe class imbalance using custom SMOTE implementation\"\"\"\n        print(f\"\\nOriginal class distribution:\")\n        print(f\"Class 0: {sum(y_train == 0):,} ({sum(y_train == 0)/len(y_train)*100:.2f}%)\")\n        print(f\"Class 1: {sum(y_train == 1):,} ({sum(y_train == 1)/len(y_train)*100:.2f}%)\")\n        \n        # Convert to numpy arrays for easier manipulation\n        if hasattr(X_train, 'values'):\n            X_train_np = X_train.values\n        else:\n            X_train_np = X_train\n            \n        if hasattr(y_train, 'values'):\n            y_train_np = y_train.values\n        else:\n            y_train_np = y_train\n        \n        if method == 'smote':\n            # Simple oversampling with noise\n            minority_class = 1\n            majority_class = 0\n            \n            minority_indices = np.where(y_train_np == minority_class)[0]\n            majority_count = np.sum(y_train_np == majority_class)\n            minority_count = len(minority_indices)\n            \n            # Generate synthetic samples to balance classes\n            samples_needed = majority_count - minority_count\n            \n            if samples_needed > 0:\n                # Get minority samples\n                minority_samples = X_train_np[minority_indices]\n                \n                # Generate synthetic samples with small random noise\n                np.random.seed(42)\n                synthetic_samples = []\n                for _ in range(samples_needed):\n                    # Pick random minority sample and add noise\n                    idx = np.random.choice(len(minority_samples))\n                    sample = minority_samples[idx].copy()\n                    noise = np.random.normal(0, 0.01, sample.shape)\n                    synthetic_samples.append(sample + noise)\n                \n                # Combine original and synthetic data\n                X_resampled = np.vstack([X_train_np, np.array(synthetic_samples)])\n                y_resampled = np.hstack([y_train_np, np.ones(samples_needed)])\n            else:\n                X_resampled, y_resampled = X_train_np, y_train_np\n                \n        elif method == 'combine':\n            # First oversample minority class partially\n            minority_indices = np.where(y_train_np == 1)[0]\n            majority_count = np.sum(y_train_np == 0)\n            \n            # Oversample to 10% of majority class\n            target_minority = int(majority_count * 0.1)\n            current_minority = len(minority_indices)\n            \n            if target_minority > current_minority:\n                samples_needed = target_minority - current_minority\n                minority_samples = X_train_np[minority_indices]\n                \n                np.random.seed(42)\n                synthetic_samples = []\n                for _ in range(samples_needed):\n                    idx = np.random.choice(len(minority_samples))\n                    sample = minority_samples[idx].copy()\n                    noise = np.random.normal(0, 0.01, sample.shape)\n                    synthetic_samples.append(sample + noise)\n                \n                X_temp = np.vstack([X_train_np, np.array(synthetic_samples)])\n                y_temp = np.hstack([y_train_np, np.ones(samples_needed)])\n            else:\n                X_temp, y_temp = X_train_np, y_train_np\n            \n            # Then undersample majority class\n            majority_indices = np.where(y_temp == 0)[0]\n            minority_count_new = np.sum(y_temp == 1)\n            target_majority = int(minority_count_new * 2)  # 2:1 ratio\n            \n            if len(majority_indices) > target_majority:\n                np.random.seed(42)  # Set seed for reproducibility\n                selected_majority = np.random.choice(majority_indices, target_majority, replace=False)\n                minority_indices_new = np.where(y_temp == 1)[0]\n                \n                selected_indices = np.hstack([selected_majority, minority_indices_new])\n                X_resampled = X_temp[selected_indices]\n                y_resampled = y_temp[selected_indices]\n            else:\n                X_resampled, y_resampled = X_temp, y_temp\n                \n        else:  # 'none'\n            X_resampled, y_resampled = X_train_np, y_train_np\n            \n        print(f\"\\nResampled class distribution ({method}):\")\n        print(f\"Class 0: {sum(y_resampled == 0):,} ({sum(y_resampled == 0)/len(y_resampled)*100:.2f}%)\")\n        print(f\"Class 1: {sum(y_resampled == 1):,} ({sum(y_resampled == 1)/len(y_resampled)*100:.2f}%)\")\n        \n        return X_resampled, y_resampled\n    \n    def custom_cross_validation(self, model, X, y, cv_folds=5):\n        \"\"\"Custom cross-validation using the composite score\"\"\"\n        # Convert to numpy arrays if needed\n        if hasattr(X, 'values'):\n            X_np = X.values\n        else:\n            X_np = X\n            \n        if hasattr(y, 'values'):\n            y_np = y.values\n        else:\n            y_np = y\n        \n        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n        \n        cv_scores = []\n        detailed_scores = []\n        \n        for fold, (train_idx, val_idx) in enumerate(cv.split(X_np, y_np)):\n            X_train_fold, X_val_fold = X_np[train_idx], X_np[val_idx]\n            y_train_fold, y_val_fold = y_np[train_idx], y_np[val_idx]\n            \n            # Train model on fold\n            model_fold = model.__class__(**model.get_params())\n            model_fold.fit(X_train_fold, y_train_fold)\n            \n            # Get predictions and probabilities\n            y_pred_fold = model_fold.predict(X_val_fold)\n            y_prob_fold = model_fold.predict_proba(X_val_fold)[:, 1]\n            \n            # Calculate composite score\n            scores = calculate_composite_score(y_val_fold, y_pred_fold, y_prob_fold, self.N)\n            cv_scores.append(scores['composite_score'])\n            detailed_scores.append(scores)\n        \n        return np.array(cv_scores), detailed_scores\n    \n    def train_models(self, X_train, y_train, use_resampling=True):\n        \"\"\"Train multiple models with custom evaluation metrics\"\"\"\n        \n        # Handle class imbalance if requested\n        if use_resampling:\n            X_train_balanced, y_train_balanced = self.handle_class_imbalance(X_train, y_train, 'combine')\n        else:\n            # Convert to numpy arrays\n            if hasattr(X_train, 'values'):\n                X_train_balanced = X_train.values\n            else:\n                X_train_balanced = X_train\n            if hasattr(y_train, 'values'):\n                y_train_balanced = y_train.values\n            else:\n                y_train_balanced = y_train\n        \n        # Define models\n        models = {\n            'RandomForest_Balanced': RandomForestClassifier(\n                n_estimators=200,\n                max_depth=15,\n                min_samples_split=10,\n                min_samples_leaf=5,\n                class_weight='balanced',\n                random_state=42,\n                n_jobs=-1\n            ),\n            \n            'RandomForest_Resampled': RandomForestClassifier(\n                n_estimators=200,\n                max_depth=15,\n                min_samples_split=10,\n                min_samples_leaf=5,\n                random_state=42,\n                n_jobs=-1\n            ),\n            \n            'XGBoost_GPU': XGBClassifier(\n                n_estimators=500,\n                learning_rate=0.05,\n                max_depth=8,\n                subsample=0.8,\n                colsample_bytree=0.8,\n                objective='binary:logistic',\n                use_label_encoder=False,\n                eval_metric='logloss',\n                tree_method='gpu_hist',\n                predictor='gpu_predictor',\n                random_state=42,\n                verbosity=0,\n                n_jobs=-1\n            ),\n            'LogisticRegression': LogisticRegression(\n                class_weight='balanced',\n                random_state=42,\n                max_iter=1000,\n                C=0.1\n            )\n        }\n        \n        print(f\"\\n{'='*80}\")\n        print(\"TRAINING MODELS WITH CUSTOM EVALUATION METRICS\")\n        print(f\"{'='*80}\")\n        print(f\"Using composite score: (AUC + Balanced Accuracy + Fraud Capture Rate@{self.N}) / 3\")\n        print(f\"{'='*80}\")\n        \n        for name, model in models.items():\n            print(f\"\\nTraining {name}...\")\n            \n            try:\n                # Choose training data based on model type\n                if 'Resampled' in name and use_resampling:\n                    X_train_model = X_train_balanced\n                    y_train_model = y_train_balanced\n                else:\n                    # Convert to numpy arrays for consistency\n                    if hasattr(X_train, 'values'):\n                        X_train_model = X_train.values\n                    else:\n                        X_train_model = X_train\n                    if hasattr(y_train, 'values'):\n                        y_train_model = y_train.values\n                    else:\n                        y_train_model = y_train\n                \n                # Train model\n                model.fit(X_train_model, y_train_model)\n                \n                # Custom cross-validation on original data\n                cv_scores, detailed_scores = self.custom_cross_validation(model, X_train, y_train)\n                \n                # Calculate average detailed scores\n                avg_detailed_scores = {\n                    'auc': np.mean([s['auc'] for s in detailed_scores]),\n                    'balanced_accuracy': np.mean([s['balanced_accuracy'] for s in detailed_scores]),\n                    'fraud_capture_rate': np.mean([s['fraud_capture_rate'] for s in detailed_scores]),\n                    'composite_score': cv_scores.mean()\n                }\n                \n                # Store model and scores\n                self.models[name] = model\n                self.model_scores[name] = {\n                    'cv_mean': cv_scores.mean(),\n                    'cv_std': cv_scores.std(),\n                    'cv_scores': cv_scores,\n                    'detailed_scores': avg_detailed_scores\n                }\n                \n                print(f\"✓ {name} Results:\")\n                print(f\"   Composite Score: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n                print(f\"   - AUC: {avg_detailed_scores['auc']:.4f}\")\n                print(f\"   - Balanced Accuracy: {avg_detailed_scores['balanced_accuracy']:.4f}\")\n                print(f\"   - Fraud Capture Rate@{self.N}: {avg_detailed_scores['fraud_capture_rate']:.4f}\")\n                \n            except Exception as e:\n                print(f\"✗ {name} failed: {str(e)}\")\n        \n        return self.models, self.model_scores\n    \n    def evaluate_models(self, X_train, y_train):\n        \"\"\"Evaluate all trained models using custom metrics\"\"\"\n        print(f\"\\n{'='*80}\")\n        print(\"MODEL EVALUATION RESULTS\")\n        print(f\"{'='*80}\")\n        \n        # Header\n        header = f\"{'Model':<25}{'Composite':<12}{'AUC':<8}{'Bal.Acc':<10}{'FCR@485':<10}{'Std':<8}\"\n        print(header)\n        print(\"-\" * 80)\n        \n        best_score = 0\n        best_model_name = None\n        \n        for name, scores in self.model_scores.items():\n            detailed = scores['detailed_scores']\n            row = f\"{name:<25}\"\n            row += f\"{scores['cv_mean']:<12.4f}\"\n            row += f\"{detailed['auc']:<8.4f}\"\n            row += f\"{detailed['balanced_accuracy']:<10.4f}\"\n            row += f\"{detailed['fraud_capture_rate']:<10.4f}\"\n            row += f\"{scores['cv_std']:<8.4f}\"\n            print(row)\n            \n            if scores['cv_mean'] > best_score:\n                best_score = scores['cv_mean']\n                best_model_name = name\n        \n        print(f\"\\n🏆 Best model: {best_model_name}\")\n        print(f\"   Composite Score: {best_score:.4f}\")\n        \n        self.best_model = self.models[best_model_name]\n        self.best_model_name = best_model_name\n        \n        return best_model_name, best_score\n    \n    def analyze_feature_importance(self, feature_names):\n        \"\"\"Analyze feature importance from the best model\"\"\"\n        if self.best_model is None:\n            print(\"No best model found. Train models first.\")\n            return\n        \n        if hasattr(self.best_model, 'feature_importances_'):\n            importance_df = pd.DataFrame({\n                'feature': feature_names,\n                'importance': self.best_model.feature_importances_\n            }).sort_values('importance', ascending=False)\n            \n            self.feature_importance = importance_df\n            \n            print(f\"\\n{'='*60}\")\n            print(f\"TOP 20 MOST IMPORTANT FEATURES ({self.best_model_name})\")\n            print(f\"{'='*60}\")\n            \n            for i, row in importance_df.head(20).iterrows():\n                print(f\"{row['feature']:<35} {row['importance']:<10.6f}\")\n            \n            return importance_df\n        else:\n            print(\"Selected model doesn't have feature_importances_ attribute\")\n            return None\n    \n    def make_predictions(self, X_test):\n        \"\"\"Make predictions on test set with detailed analysis\"\"\"\n        if self.best_model is None:\n            print(\"No best model found. Train and evaluate models first.\")\n            return None\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"MAKING PREDICTIONS WITH {self.best_model_name}\")\n        print(f\"{'='*60}\")\n        \n        # Convert to numpy array if needed\n        if hasattr(X_test, 'values'):\n            X_test_np = X_test.values\n        else:\n            X_test_np = X_test\n        \n        # Get predictions and probabilities\n        predictions = self.best_model.predict(X_test_np)\n        probabilities = self.best_model.predict_proba(X_test_np)[:, 1]\n        \n        # Analysis of predictions\n        print(f\"Total predictions: {len(predictions):,}\")\n        print(f\"Predicted laundering cases: {sum(predictions):,} ({sum(predictions)/len(predictions)*100:.2f}%)\")\n        \n        # Probability analysis\n        print(f\"\\nProbability Analysis:\")\n        print(f\"- Mean probability: {probabilities.mean():.4f}\")\n        print(f\"- Max probability: {probabilities.max():.4f}\")\n        print(f\"- Min probability: {probabilities.min():.4f}\")\n        print(f\"- Std probability: {probabilities.std():.4f}\")\n        \n        # Top N analysis for submission\n        top_N_indices = np.argsort(probabilities)[::-1][:self.N]\n        top_N_probs = probabilities[top_N_indices]\n        \n        print(f\"\\nTop {self.N} Predictions Analysis:\")\n        print(f\"- Probability range: {top_N_probs.min():.4f} to {top_N_probs.max():.4f}\")\n        print(f\"- Mean probability: {top_N_probs.mean():.4f}\")\n        print(f\"- Predictions flagged as laundering: {sum(predictions[top_N_indices])}\")\n        \n        return predictions, probabilities\n    \n    def create_submission(self, predictions, probabilities, output_file='money_laundering_predictions.csv'):\n        \"\"\"Create submission file with detailed analysis\"\"\"\n        # Create submission dataframe\n        submission_df = pd.DataFrame({\n            'Id': range(len(predictions)),\n            'Prediction': predictions,\n            'Probability': probabilities\n        })\n        \n        # Save to file\n        submission_df.to_csv(output_file, index=False)\n        \n        print(f\"\\n{'='*60}\")\n        print(\"SUBMISSION CREATED\")\n        print(f\"{'='*60}\")\n        print(f\"File: {output_file}\")\n        print(f\"Total cases: {len(predictions):,}\")\n        print(f\"Predicted laundering: {sum(predictions):,}\")\n        print(f\"Top {self.N} cases for review (highest probabilities)\")\n        \n        # Show top 10 cases\n        print(f\"\\nTop 10 highest probability cases:\")\n        print(submission_df.head(10)[['Id', 'Prediction', 'Probability']].to_string(index=False))\n        \n        return submission_df\n\ndef train_and_evaluate_models(X_train, y_train, X_test, feature_names):\n    \"\"\"Complete pipeline for model training and evaluation with custom metrics\"\"\"\n    \n    # Initialize trainer\n    trainer = MoneyLaunderingModelTrainer()\n    \n    # Train models\n    trainer.train_models(X_train, y_train, use_resampling=True)\n    \n    # Evaluate models\n    best_model_name, best_score = trainer.evaluate_models(X_train, y_train)\n    \n    # Analyze feature importance\n    feature_importance = trainer.analyze_feature_importance(feature_names)\n    \n    # Make predictions\n    predictions, probabilities = trainer.make_predictions(X_test)\n    \n    # Create submission\n    submission_df = trainer.create_submission(predictions, probabilities)\n    \n    return trainer, submission_df, predictions, probabilities, feature_importance\n\ndef print_evaluation_methodology():\n    \"\"\"Print explanation of the evaluation methodology\"\"\"\n    print(f\"\\n{'='*80}\")\n    print(\"EVALUATION METHODOLOGY\")\n    print(f\"{'='*80}\")\n    \n    methodology = \"\"\"\nThis model uses a composite evaluation score combining three key metrics:\n\n1. AUC (Area Under the Curve):\n   - Measures the model's ability to distinguish between fraudulent and legitimate transactions\n   - Range: 0 to 1 (higher is better)\n   - Particularly important for imbalanced datasets\n\n2. Balanced Accuracy:\n   - Average of True Positive Rate (TPR) and True Negative Rate (TNR)\n   - Formula: (TPR + TNR) / 2\n   - Ensures good performance on both classes despite imbalance\n\n3. Fraud Capture Rate (Top 485 Predictions):\n   - Proportion of actual fraudulent transactions found in top 485 highest-probability predictions\n   - Formula: (Frauds in Top 485) / (Total Frauds in Dataset)\n   - Critical for real-world AML systems with limited investigation capacity\n\nFinal Composite Score:\n   - Arithmetic mean of the three metrics: (AUC + Balanced Accuracy + FCR@485) / 3\n   - Balances detection performance with practical investigation constraints\n\"\"\"\n    \n    print(methodology)\n    print(f\"{'='*80}\")\n\n# Call this to understand the evaluation approach\nprint_evaluation_methodology()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:25:51.649724Z","iopub.execute_input":"2025-06-16T00:25:51.650361Z","iopub.status.idle":"2025-06-16T00:25:51.688261Z","shell.execute_reply.started":"2025-06-16T00:25:51.650343Z","shell.execute_reply":"2025-06-16T00:25:51.687472Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nEVALUATION METHODOLOGY\n================================================================================\n\nThis model uses a composite evaluation score combining three key metrics:\n\n1. AUC (Area Under the Curve):\n   - Measures the model's ability to distinguish between fraudulent and legitimate transactions\n   - Range: 0 to 1 (higher is better)\n   - Particularly important for imbalanced datasets\n\n2. Balanced Accuracy:\n   - Average of True Positive Rate (TPR) and True Negative Rate (TNR)\n   - Formula: (TPR + TNR) / 2\n   - Ensures good performance on both classes despite imbalance\n\n3. Fraud Capture Rate (Top 485 Predictions):\n   - Proportion of actual fraudulent transactions found in top 485 highest-probability predictions\n   - Formula: (Frauds in Top 485) / (Total Frauds in Dataset)\n   - Critical for real-world AML systems with limited investigation capacity\n\nFinal Composite Score:\n   - Arithmetic mean of the three metrics: (AUC + Balanced Accuracy + FCR@485) / 3\n   - Balances detection performance with practical investigation constraints\n\n================================================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Your existing usage remains the same\ntrainer, submission_df, predictions, probabilities, feature_importance = train_and_evaluate_models(\n    X_train, y_train, X_test, feature_names\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:25:51.688969Z","iopub.execute_input":"2025-06-16T00:25:51.689212Z","iopub.status.idle":"2025-06-16T00:28:41.739781Z","shell.execute_reply.started":"2025-06-16T00:25:51.689189Z","shell.execute_reply":"2025-06-16T00:28:41.739075Z"}},"outputs":[{"name":"stdout","text":"\nOriginal class distribution:\nClass 0: 54,621 (98.76%)\nClass 1: 686 (1.24%)\n\nResampled class distribution (combine):\nClass 0: 10,924 (66.67%)\nClass 1: 5,462 (33.33%)\n\n================================================================================\nTRAINING MODELS WITH CUSTOM EVALUATION METRICS\n================================================================================\nUsing composite score: (AUC + Balanced Accuracy + Fraud Capture Rate@485) / 3\n================================================================================\n\nTraining RandomForest_Balanced...\n✓ RandomForest_Balanced Results:\n   Composite Score: 0.9982 ± 0.0024\n   - AUC: 0.9997\n   - Balanced Accuracy: 0.9964\n   - Fraud Capture Rate@485: 0.9985\n\nTraining RandomForest_Resampled...\n✓ RandomForest_Resampled Results:\n   Composite Score: 0.9983 ± 0.0013\n   - AUC: 0.9999\n   - Balanced Accuracy: 0.9949\n   - Fraud Capture Rate@485: 1.0000\n\nTraining XGBoost_GPU...\n✓ XGBoost_GPU Results:\n   Composite Score: 0.9993 ± 0.0006\n   - AUC: 1.0000\n   - Balanced Accuracy: 0.9978\n   - Fraud Capture Rate@485: 1.0000\n\nTraining LogisticRegression...\n✓ LogisticRegression Results:\n   Composite Score: 0.9808 ± 0.0050\n   - AUC: 0.9950\n   - Balanced Accuracy: 0.9576\n   - Fraud Capture Rate@485: 0.9898\n\n================================================================================\nMODEL EVALUATION RESULTS\n================================================================================\nModel                    Composite   AUC     Bal.Acc   FCR@485   Std     \n--------------------------------------------------------------------------------\nRandomForest_Balanced    0.9982      0.9997  0.9964    0.9985    0.0024  \nRandomForest_Resampled   0.9983      0.9999  0.9949    1.0000    0.0013  \nXGBoost_GPU              0.9993      1.0000  0.9978    1.0000    0.0006  \nLogisticRegression       0.9808      0.9950  0.9576    0.9898    0.0050  \n\n🏆 Best model: XGBoost_GPU\n   Composite Score: 0.9993\n\n============================================================\nTOP 20 MOST IMPORTANT FEATURES (XGBoost_GPU)\n============================================================\nto_unique_senders                   0.308360  \npair_frequency                      0.255531  \nPayment Type                        0.069474  \nto_tx_count                         0.058201  \namount_x_payment_type               0.054149  \nto_in_degree_centrality             0.053917  \nfrom_tx_count                       0.051064  \nfrom_unique_recipients              0.035715  \nto_min_amount                       0.015099  \nfrom_payment_types                  0.014775  \nfrom_min_amount                     0.012532  \nto_payment_types                    0.011295  \nfrom_betweenness_centrality         0.009589  \nfrom_std_amount                     0.005664  \nto_betweenness_centrality           0.004531  \nto_total_amount                     0.003489  \nreverse_pair_frequency              0.003250  \nfrom_out_degree_centrality          0.003167  \nfrom_max_amount                     0.002635  \nto_std_amount                       0.002455  \n\n============================================================\nMAKING PREDICTIONS WITH XGBoost_GPU\n============================================================\nTotal predictions: 23,743\nPredicted laundering cases: 302 (1.27%)\n\nProbability Analysis:\n- Mean probability: 0.0128\n- Max probability: 1.0000\n- Min probability: 0.0000\n- Std probability: 0.1116\n\nTop 485 Predictions Analysis:\n- Probability range: 0.0022 to 1.0000\n- Mean probability: 0.6233\n- Predictions flagged as laundering: 302\n\n============================================================\nSUBMISSION CREATED\n============================================================\nFile: money_laundering_predictions.csv\nTotal cases: 23,743\nPredicted laundering: 302\nTop 485 cases for review (highest probabilities)\n\nTop 10 highest probability cases:\n Id  Prediction  Probability\n  0           0     0.000056\n  1           0     0.000061\n  2           0     0.000045\n  3           0     0.000096\n  4           1     0.999675\n  5           0     0.000033\n  6           0     0.000131\n  7           1     0.999677\n  8           1     0.999675\n  9           1     0.999710\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"with open(\"submission.txt\", \"w\") as f:\n    for pred, prob in zip(predictions, probabilities):\n        f.write(f\"{prob} {pred}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T00:28:41.740533Z","iopub.execute_input":"2025-06-16T00:28:41.740772Z","iopub.status.idle":"2025-06-16T00:28:41.784600Z","shell.execute_reply.started":"2025-06-16T00:28:41.740753Z","shell.execute_reply":"2025-06-16T00:28:41.784055Z"}},"outputs":[],"execution_count":7}]}